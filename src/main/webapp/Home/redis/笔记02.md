**redis原理分析** 
        
过期时间的设置以及原理： 

        set name wangt
        expire name 5 (5 seconds单位是秒)  1表示设置成功    pexpire的设置单位是毫秒 
        ttl name    查看还剩于秒  -2 表示key不存在  没有指定过期时间返回-1   pttl的单位是毫秒
        pesist name 接触过期时间限制 （得当前key有效哦 ） 1 表示OK   0 表示键不存在或者本身该键就是永久的
        setex(string value .int seconds . string value)
        
        setnx key value----分布式锁： 将 key 的值设为 value ，当且仅当 key 不存在时成功。 若给定的 key 已经存在，则 SETNX 不做任何动作。
        
        原理
            消极方法    在主键被访问的时候 如果发现它已经失效，那么就删除它！
            积极方法    周期性的从被设置了时间的主键中选择一部分失效的进行删除 （异类：对于那些已经设置了过期时间，但是从未查询它 那么这种方式无法被删除）
                        所以redis会周期性的随机测试一些设置了过期时间的key 已经过期将会被主动删除。   
                        redis会每10秒进行这项检查操作——流程：
                            1 随机测试20个带有时间设置的key
                            2 删除其中已经过期的key
                            3 如果删除key的个数占比25%  重复1操作 如此往复
                            
                            这是一个简单的概率算法，基于假设我们随机抽取的key代表了全部的key空间
        那么有可能某个失效的key始终都删不掉？？
        
发布与订阅： 
        
         pattern channel
         PUBLISH channelName message
         SUBSCRIBE channelName  
         
数据是如何持久化的 RDB:

        当符合一定条件时，Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，等
            到持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作
            的，这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方
            式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失
            
            --fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和
            原进程一致，但是是一个全新的进程，并作为原进程的子进程 （类似于创建分身 耗时间性能）
            
            Redis会在以下几种情况下对数据进行快照
            1. 根据配置规则进行自动快照
            2. 用户执行SAVE或者GBSAVE命令   save 是会阻塞的   dbsave 后台进程进行快照
            3. 执行FLUSHALL命令  类似于备份
            4. 执行复制(replication)时 
            缺点：最后一次持久化后的数据可能丢失
            
数据是如何持久化的AOF: 

            从rdb切换到aof会加载aof 的文件（优先aof）
            当使用Redis存储非临时数据时，一般需要打开AOF持久化来降低进程终止导致的数据丢失。AOF可以将Redis执行的每一条写命令追加到硬盘文件中，
            这一过程会降低Redis的性能，但大部分情况下这个影响是能够接受的，另外使用较快的硬盘可以提高AOF的性能
            在redis.conf 中找到 appendonly yes 表示开启aof 模式   rdb，aof2种模式可以同时开启
            set foo 1
            set foo 2
            set foo 3
        vim 可以直接看到 appendonly.aof  文件的内容  是一个追加写入的方式  
            
            我们会发现AOF文件的内容正是Redis发送的原始通信协议的内容，从内容中我们发现Redis只记录了3条命令。然后这时有一个问题是前面2条命令其实是冗余的，
            因为这两条的执行结果都会被第三条命令覆盖。随着执行的命令越来越多，AOF文件的大小也会越来越大，其实内存中实际的数据可能没有多少，
            那这样就会造成磁盘空间以及redis数据还原的过程比较长的问题。因此我们希望Redis可以自动优化AOF文件，就上面这个例子来说，前面两条是可以被删除的。 
            而实际上Redis也考虑到了，可以配置一个条件，每当达到一定条件时Redis就会自动重写AOF文件，这个条件的配置为 
            auto-aof-rewritepercentage 100 表示的是当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时AOF文件大小为依据
            auto-aof-rewrite-min-size 64mb   表示限制了允许重写的最小AOF文件大小64mb，通常在AOF文件很小的情况下即使其中有很多冗余的命令我们也并不太关心。
            
        另外，还可以通过BGREWRITEAOF 命令手动执行AOF，执行完以后冗余的命令已经被删除了在启动时，Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相对于RDB会慢一些
         
         AOF 的重写原理：
             Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。
             重写的流程是：
                主进程会fork一个子进程出来进行AOF重写，这个重写过程并不是基于原有的aof文件来做的，而是有点类似于内存快照的方式，全量遍历内存中的数据，
                然后逐个序列到aof文件中。在fork子进程这个过程中，服务端仍然可以对外提供服务，那这个时候重写的aof文件的数据和redis内存数据不一致了怎么办？
                不用担心，这个过程中，主进程的数据更新操作，会缓存到aof_rewrite_buf中，也就是单独开辟一块缓存来存储重写期间收到的命令，当子进程重写完以后
                再把缓存中的数据追加到新的aof文件。当所有的数据全部追加到新的aof文件中后，把新的aof文件重命名为appendonly.aof，此后所有的操作都会被写入新的aof文件。
                
                如果在rewrite过程中出现故障，不会影响原来aof文件的正常工作，只有当rewrite完成后才会切换文件。因此这个rewrite过程是比较可靠的
                  
redis的内存回收策略：
        
        当内存不足的时候 redis 不得不淘汰掉一些key释放内存空间 ，如何选择，redis提供了多种内存回收策略：
            1 noeviction 默认策略 当内存达到阈值的时候  所有引起申请内存的操作的命令会报错！  （提示管理员应该处理了）
            2 allkeys-lru 从数据集中挑选最近最少使用的数据淘汰掉 (如果我们的应用堆缓存的访问都是一些热点数据，那么可以使用该方式)
            3 allkeys-random 随机移除某个key
             
            4 volatile-random 从已设置了过期时间的随机库的数据集中 （server.db[i].expire） 中任意选择数据淘汰
            5 volatile-lru 从已经设置了过期时间的随机库中的数据集中 选择近期最少使用的数据进行淘汰
            6 volatile-ttl 从已经设置了过期时间的随机库中的数据集中 挑选即将要过期的数据进行淘汰
            这种策略使得我们可以向Redis提示哪些key更适合被淘汰，我们可以自己控制
            总结：
                实际上Redis实现的LRU并不是可靠的LRU，也就是名义上我们使用LRU算法淘汰内存数据，但是实际上被淘汰的键并不一定是真正的最少使用的数据，
                这里涉及到一个权衡的问题，如果需要在所有的数据中搜索最符合条件的数据，那么一定会增加系统的开销，Redis是单线程的，所以耗时的操作会谨慎一些。
                为了在一定成本内实现相对的LRU，早期的Redis版本是基于采样的LRU，也就是放弃了从所有数据中搜索解改为采样空间搜索最优解。Redis3.0版本之后，
                Redis作者对于基于采样的LRU进行了一些优化，目的是在一定的成本内让结果更靠近真实的LRU。

Redis重启时加载持久化文件的顺序：
    
    1 Redis重启的时候优先加载AOF文件，如果AOF文件不存在再去加载RDB文件。
    2 如果AOF文件和RDB文件都不存在，那么直接启动。
    3 不论加载AOF文件还是RDB文件，只要发生错误都会打印错误信息，并且启动失败。
                
单线程的redis性能好的原由：              
    
    IO多路复用？<待详细总结>
    
    1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；
    2、数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；
    3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
    4、使用多路I/O复用模型，非阻塞IO；
    5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；
    以上几点都比较好理解，下边我们针对多路 I/O 复用模型进行简单的探讨：
    （1）多路 I/O 复用模型
        多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，
    于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。
    这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，
    也就是说内存内的操作不会成为影响Redis性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量
        
        
        
        
        
        
        
        
        
        
        
        