**分布式redis**

redis主从机制
    
    如何避免单点故障：主从复制
        复制的作用是把redis的数据库复制多个副本部署在不同的服务器上，如果其中一台服务器出现故障，也能快速迁移到其他服务器上提供服务。
    复制功能可以实现当一台redis服务器的数据更新后，自动将新的数据同步到其他服务器上主从复制就是我们常见的master/slave模式， 
    主数据库可以进行读写操作，当写操作导致数据发生变化时会自动将数据同步给从数据库。而一般情况下，从数据库是只读的，
    并接收主数据库同步过来的数据。 一个主数据库可以有多个从数据库
    配置: slaveof  127.0.0.1 6379
    
    原理：
        全量复制：
            redis全量复制一般都是发生在slave初始化阶段，这个时候slave需要将master 的所有数据都来copy一份。步骤：
                1 从服务器发送sync命令给主服务器
                2 主服务器bgsave（fork子进程）生成快照，并记录在此期间的写命令。同步完了之后直接进行增量操作
                3 发送快照到从服务器(2.8+版本之后支持断点续传)
                4 发送2缓存的写命令（后续进行增量复制）
            如果1主N从，如果在往从服务器同步命令的时候，这个时候master 的网络突然断开了呢????
                redis 提供了一个配置项是来限制只有数据同步给了多少个slave的时候  maser才是可以写的。
                min-slaves-to-write 3 表示只有当3个或以上的slave连接到master，master才是可写的
                min-slaves-max-lag 10 表示允许slave最长失去连接的时间，如果10秒还没收到slave的响应，则master认为该slave以断开                
                （有点类似zk）
        增量复制：
                从redis 2.8开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，
            而不是从头开始复制一份master node会在内存中创建一个backlog，master和slave都会保存一个replica offset还有一个master id，offset就是保存在backlog中的。
            如果master和slave网络连接断掉了，slave会让master从上次的replica offset开始继续复制但是如果没有找到对应的offset，
            才执行一次全量同步
            
        无硬盘复制：
            前面，redis复制的工作原理基于RDB方式的持久化实现的，也就是master在后台保存RDB快照，slave接收到rdb文件并载入，
            但是这种方式会存在一些问题\
                1. 当master禁用RDB时，如果执行了复制初始化操作，Redis依然会生成RDB快照，当master下次启动时执行该RDB文件的恢复，
                    但是因为复制发生的时间点不确定，所以恢复的数据可能是任何时间点的。就会造成数据出现问题\
                2. 当硬盘性能比较慢的情况下（网络硬盘），那初始化复制过程会对性能产生影响因此2.8.18以后的版本，Redis引入了无硬盘复制选项，
                    可以不需要通过RDB文件去同步，直接发送数据，通过以下配置来开启该功能repl-diskless-sync yes master在内存中直接创建rdb数据，
                    然后发送给slave，那么数据不会在自己本地落地磁盘同步了
    
哨兵机制
        
        哨兵的功能：
        1  监控master 和slave 的运行情况
        2  master 出现故障的时候，自动将slave选举初leader
        哨兵是一个独立的进程 （哨兵也是可以配置多个的  就是为了避免哨兵挂掉然后leader也挂掉的情况）
        也就是说：  为了解决master选举问题，又引出了一个单点问题，也就是哨兵的可用性如何解决，在一个一主多从的Redis系统中，
                    可以使用多个哨兵进行监控任务以保证系统足够稳定。此时哨兵不仅会监控master和slave，同时还会互相监控；这种方式称为哨兵集群，
                    哨兵集群需要解决故障发现、和master决策的协商机制问题
        
        sentinel节点之间会因为共同监视同一个master从而产生了关联，一个新加入的sentinel节点需要和其他监视相同master节点的sentinel相互感知,步骤:
            1  需要相互感知的sentinel都向他们共同监视的master节点订阅<信息> channel:sentinel:hello
            2  新加入的sentinel节点向这个channel发布一条消息，包含自己本身的信息，这样订阅了这个channel的sentinel
               就可以发现这个新的sentinel
            3  新加入得sentinel和其他sentinel节点建立长连接               
        sentinel节点 也会有一个master  是通过sentinel-master 来选举redis集群的新的learder
           扩展：  sentinel节点会定期向master节点发送心跳包来判断存活状态，一旦master节点没有正确响应，sentinel会把
                master设置为“主观不可用状态”，然后它会把“主观不可用”发送给其他所有的sentinel节点去确认，当确认的
                sentinel节点数大于>quorum时，则会认为master是“客观不可用”，接着就开始进入选举新的master流程；但是
                这里又会遇到一个问题，就是sentinel中，本身是一个集群，如果多个节点同时发现master节点达到客观不可用状
                态，那谁来决策选择哪个节点作为maste呢？这个时候就需要从sentinel集群中选择一个leader来做决策。而这里
                用到了一致性算法Raft算法、它和Paxos算法类似，都是分布式一致性算法。但是它比Paxos算法要更容易理解；
                Raft和Paxos算法一样，也是基于投票算法，只要保证过半数节点通过提议即可;
        Raft算法：动画演示地址：http://thesecretlivesofdata.com/raft/
                大致意思就是：谁先发现sentinel-master不见了 谁就向所有sentinel节点发起一次投票，你们都投我 我来当sentinel-master。然后大家就投票了
                实行超过半数制
        
        sentinel monitor name ip port quoru
            --其中name表示要监控的master的名字，这个名字是自己定义。 ip和port表示master的ip和端口号。 
            最后一个1表示最低 通过票数，也就是说至少需要几个哨兵节点统一才可以，后面会具体讲解  
            例子:sentinel monitor mymaster 192.168.11.131 6379 1
        sentinel down-after-milliseconds mymaster 5000 
            --表示如果5s内mymaster没响应，就认为SDOWN
        sentinel failover-timeout mymaster 15000 
            --表示如果15秒后,mysater仍没活过来，则启动failover，从剩下的slave中选一个升级为master
        启动 redis-sentinel sentinel.conf  redis-server /path/to/sentinel.conf --sentinel
        
        
redis-cluster（数据分片集群）
    
        3主3从——数据路由分片到3个不同的小分片集群中， 3个小分片集群自由合理分配1-16383个槽位。 路由到哪个槽位，数据就放哪台机器。每一个节点负责维护一部分槽以及槽所映射的键值数据
        分片集群扩容，缩容——槽位的重新分配，数据的迁移，迁移过程中的数据访问。。。
        slot = CRC16(key)%16383 
        分片集群数据落地流程：
            1 set hello world
            2 CRC6（key）%16383 获得槽位值
            3 数据落点到槽位节点（如果该槽位节点没有该数据，返回move标识，并且告知该数据在哪一个节点上）
        分片集群扩容流程：A（123）--->B（）比如现在需要把A节点的123槽位数据迁移到新加入进来的B节点，一下问题：
                    AB两个节点建立连接，准备迁移数据之前，会吧123槽位范围打一个状态标签。比如发送方——接收方
            1 迁移过程中，如果需要访问123槽位数据，这个时候会返回一个（迁移的状态） 并告知请求应该去哪一个节点上去访问数据
            2 如果到达新的节点的请求发现数据还是处于接收状态，还没有接收完成，则会等待，否则直接处理该请求。如果没有该数据会跳转到本来数据应该存在的节点服务器
            
                当MasterB的状态设置为IMPORTING后，表示对应的slot正在向MasterB迁入，此时Master仍然能对外提供该slot
            的读写服务，但和通常状态下也是有区别的
            \1. 当来自客户端的正常访问不是从ASK跳转过来的，说明客户端还不知道迁移正在进行，很有可能操作了一个目前
            还没迁移完成的并且还存在于MasterA上的key，如果此时这个key在A上已经被修改了，那么B和A的修改则会发生
            冲突。所以对于MasterB上的slot上的所有非ASK跳转过来的操作，MasterB都不会uu出去护理，而是通过MOVED
            命令让客户端跳转到MasterA上去执行
            这样的状态控制保证了同一个key在迁移之前总是在源节点上执行，迁移后总是在目标节点上执行，防止出现两边
            同时写导致的冲突问题。而且迁移过程中新增的key一定会在目标节点上执行，源节点也不会新增key，是的整个迁
            移过程既能对外正常提供服务，又能在一定的时间点完成slot的迁移。
                

        
        